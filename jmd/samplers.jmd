# Samplers

Load required packages
```julia; results = "hidden"
using LinearAlgebra, Random, Printf
using NNlib, Zygote, BenchmarkTools, CUDA
using Flux: onecold
using StatsBase: kldivergence
using SpinModels
```

## Set-up

```julia; results = "hidden"
function randdata(P = 50, q = 21, N = 59, M = 256)
    z = Float32.(1:q .== rand(1:q, 1, N, M))
    Î¸ = SRBM(N = N, P = P, q = q, similarto = z)
    @. Î¸.J = randn()
    @. Î¸.h = randn()
    if hasproperty(Î¸, :W)
        @. Î¸.W = randn()
        @. Î¸.b = randn()
    end
    if CUDA.functional()
        cu_z = CuArray(z)
        cu_Î¸ = SRBM(CuArray(Î¸.J), CuArray(Î¸.h), CuArray(Î¸.W), CuArray(Î¸.b))
        return z, Î¸, cu_z, cu_Î¸
    else
        return z, Î¸, nothing, nothing
    end
end
```

True probability mass distribution
```julia; results = "hidden"
function true_pmf(q, N, Î¸)
    q^N > 10^7 && error("too many states!")
    â„™ = Vector{Float32}(undef, q^N)
    x = zeros(q, N)
    inds = Vector{CartesianIndex{2}}(undef, N)
    for (n,s) âˆˆ enumerate(Iterators.product(ntuple(i -> 1:q, N)...))
        inds .= CartesianIndex.(s, 1:N)
        x[inds] .= 1
        â„™[n] = -energy(x, Î¸)[1]
        n == onehot2ind(x)[1] || error("incorrect `onehot2ind()`!")
        x[inds] .= 0
    end
    return softmax!(â„™)
end
```
Define a function for converting onehot encoded states to the state indices in the true probability vector
```julia; results = "hidden"
function onehot2ind(x)
    q, N = size(x)[1:2]
    y = collect(onecold(x, 1:q))
    return 1 .+ transpose(y.-1) * (q.^(0:N-1))
end
```
Empirical probability mass distribution
```julia; results = "hidden"
function empr_pmf(x::AbstractArray{<:Any,3})
    q, N, M = size(x)
    q^N > 10^7 && error("too many states!")
    ð•¡ = zeros(q^N)
    for n âˆˆ onehot2ind(x)
        ð•¡[n]+=1
    end
    ð•¡ .*= 1//M
    return ð•¡
end
```

Interfact to the samplers in `SpinModels`
```julia; results = "hidden"
function draw(sampler::SpinSampler, energy, zâ‚€; showevery = 50, steps = 500, true_pmf)
    z = copy(zâ‚€)
    flips = 0.0
    for i âˆˆ 0:steps
        i > 0 && sampler(z, energy)
        flips += iszero(i) ? 0 : mean(acceptrate(sampler))
        iszero(i) && @printf "step   rate  <flips>  KL[q|p]\n"
        iszero(i) && @printf "-----  ----  -------  -------\n"
        if iszero(i%showevery)
            accrate = iszero(i) ? 0 : mean(acceptrate(sampler))
            kl = kldivergence(empr_pmf(z), true_pmf, 2)
            @printf "%5d  %4.2f  %7.1f  %7.3f\n" i accrate flips kl
        end
    end
end
```

## initialize data and model

Get data, model and construct true probability vector
```julia; results = "hidden"
P, q, N, M = 20, 4, 5, 2048 # 20 hidden units, 5 4-state spins and sample size 2048
z, Î¸, cu_z, cu_Î¸ = randdata(P, q, N, M)
â„™ = true_pmf(q, N, Î¸)
```

## Matropolis-Hastings method

```julia; results = "hidden"
function init_mh(z, Î¸)
    energybuffer = EnergyBuffer(z, Î¸)
    E = x -> energy(x, Î¸, energybuffer)
    mh = MetropolisHastings(z)
    return  mh, E
end
```

```julia; term = true
draw(init_mh(z, Î¸)..., z; true_pmf = â„™)                                 # on CPU
CUDA.functional() && draw(init_mh(cu_z, cu_Î¸)..., cu_z; true_pmf = â„™)   # on GPU
```

## Gibbs with gradients

```julia; results = "hidden"
function init_gwg(z, Î¸)
    energybuffer = EnergyBuffer(z, Î¸)
    âˆ‚E = x -> (
        E  = energy(x, Î¸, energybuffer); 
        âˆ‡E = âˆ‚x_energy(x, Î¸, energybuffer); 
        (E, âˆ‡E)
    )
    gwg = GibbsWithGradients(z)
    return  gwg, âˆ‚E
end
```

```julia; term = true
draw(init_gwg(z, Î¸)..., z; true_pmf = â„™)                                # on CPU
CUDA.functional() && draw(init_gwg(cu_z, cu_Î¸)..., cu_z; true_pmf = â„™)  # on GPU
```

## Benchmarks

### Metropolis-Hastings
```julia; results = "hidden"
function benchmark_mh(M; P = 20, q = 21, N = 59, gpu = false)
    z, Î¸, cu_z, cu_Î¸ = randdata(P, q, N, M)
    if gpu && CUDA.functional()
        mh, E = init_mh(cu_z, cu_Î¸)
        @btime CUDA.@sync $mh($cu_z, $E)
    else
        mh, E = init_mh(z, Î¸)
        @btime $mh($z, $E)
    end
    (gpu & !CUDA.functional()) && @printf "No GPU"
    return nothing
end
```

Test at different numbers of parallel MC chains
```julia; term = true
benchmark_mh(100)
benchmark_mh(500)
benchmark_mh(1000)
benchmark_mh(3000)
```

```julia; term = true
benchmark_mh(100,  gpu = true)
benchmark_mh(500,  gpu = true)
benchmark_mh(1000, gpu = true)
benchmark_mh(3000, gpu = true)
```

### Gibbs with gradients
```julia; results = "hidden"
function benchmark_gwg(M; P = 20, q = 21, N = 59, gpu = false)
    z, Î¸, cu_z, cu_Î¸ = randdata(P, q, N, M)
    if gpu && CUDA.functional()
        gwg, âˆ‚E = init_gwg(cu_z, cu_Î¸)
        @btime CUDA.@sync $gwg($cu_z, $âˆ‚E)
    else
        gwg, âˆ‚E = init_gwg(z, Î¸)
        @btime $gwg($z, $âˆ‚E)
    end
    (gpu & !CUDA.functional()) && @printf "No GPU"
    return nothing
end
```

Test at different numbers of parallel MC chains
```julia; term = true
benchmark_gwg(100)
benchmark_gwg(500)
benchmark_gwg(1000)
benchmark_gwg(3000)
```

```julia; term = true
benchmark_gwg(100,  gpu = true)
benchmark_gwg(500,  gpu = true)
benchmark_gwg(1000, gpu = true)
benchmark_gwg(3000, gpu = true)
```


## System information

```julia; term = true
using InteractiveUtils; versioninfo()
```
Thread information
```julia; term = true
Sys.CPU_THREADS
BLAS.get_num_threads()
```
GPU information
```julia; term = true
CUDA.functional() && run(`nvidia-smi`);
```